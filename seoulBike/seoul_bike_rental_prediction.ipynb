{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 서울 따릉이 대여량 예측\n\n이 노트북에서는 서울시 공공자전거 '따릉이'의 대여량을 예측하는 머신러닝 모델을 구축합니다.\n\n## 목차\n1. 라이브러리 및 데이터 로드\n2. 탐색적 데이터 분석 (EDA)\n3. 데이터 전처리\n4. 특성 공학 (Feature Engineering)\n5. 모델링\n6. 모델 평가 및 비교\n7. 최종 예측 및 제출 파일 생성\n8. **AutoGluon 모델링 (NEW)**\n   - Medium Quality 모델\n   - Best Quality 모델\n   - 전체 모델 성능 비교"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. 라이브러리 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 전처리 및 모델링\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 모델\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 한글 폰트 설정 (Windows)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "\n",
    "print('라이브러리 로드 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "submission = pd.read_csv(DATA_PATH + 'submission.csv')\n",
    "\n",
    "print(f'Train shape: {train.shape}')\n",
    "print(f'Test shape: {test.shape}')\n",
    "print(f'Submission shape: {submission.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 미리보기\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼 설명\n",
    "\n",
    "| 컬럼명 | 설명 | 단위 |\n",
    "|--------|------|------|\n",
    "| id | 고유 식별자 | - |\n",
    "| hour | 시간 | 0~23시 |\n",
    "| hour_bef_temperature | 1시간 전 기온 | °C |\n",
    "| hour_bef_precipitation | 1시간 전 강수 여부 | 0(없음), 1(있음) |\n",
    "| hour_bef_windspeed | 1시간 전 풍속 | m/s |\n",
    "| hour_bef_humidity | 1시간 전 습도 | % |\n",
    "| hour_bef_visibility | 1시간 전 가시거리 | m |\n",
    "| hour_bef_ozone | 1시간 전 오존 농도 | ppm |\n",
    "| hour_bef_pm10 | 1시간 전 미세먼지(PM10) | μg/m³ |\n",
    "| hour_bef_pm2.5 | 1시간 전 초미세먼지(PM2.5) | μg/m³ |\n",
    "| **count** | **따릉이 대여량 (타겟)** | 대 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정보 확인\n",
    "print('=' * 50)\n",
    "print('Train 데이터 정보')\n",
    "print('=' * 50)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기초 통계량\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 탐색적 데이터 분석 (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 타겟 변수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수 분포\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 원본 분포\n",
    "axes[0].hist(train['count'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].set_xlabel('대여량 (count)')\n",
    "axes[0].set_ylabel('빈도')\n",
    "axes[0].set_title('따릉이 대여량 분포')\n",
    "axes[0].axvline(train['count'].mean(), color='red', linestyle='--', label=f\"평균: {train['count'].mean():.1f}\")\n",
    "axes[0].axvline(train['count'].median(), color='green', linestyle='--', label=f\"중앙값: {train['count'].median():.1f}\")\n",
    "axes[0].legend()\n",
    "\n",
    "# 로그 변환 분포\n",
    "axes[1].hist(np.log1p(train['count']), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('Log(대여량 + 1)')\n",
    "axes[1].set_ylabel('빈도')\n",
    "axes[1].set_title('따릉이 대여량 분포 (로그 변환)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"대여량 통계:\")\n",
    "print(train['count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 결측치 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인\n",
    "print('=' * 50)\n",
    "print('Train 데이터 결측치')\n",
    "print('=' * 50)\n",
    "missing_train = train.isnull().sum()\n",
    "missing_train_pct = (missing_train / len(train) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'결측치 수': missing_train, '비율(%)': missing_train_pct})\n",
    "print(missing_df[missing_df['결측치 수'] > 0])\n",
    "\n",
    "print('\\n' + '=' * 50)\n",
    "print('Test 데이터 결측치')\n",
    "print('=' * 50)\n",
    "missing_test = test.isnull().sum()\n",
    "missing_test_pct = (missing_test / len(test) * 100).round(2)\n",
    "missing_df_test = pd.DataFrame({'결측치 수': missing_test, '비율(%)': missing_test_pct})\n",
    "print(missing_df_test[missing_df_test['결측치 수'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Train 결측치\n",
    "missing_train_plot = missing_train[missing_train > 0].sort_values(ascending=True)\n",
    "if len(missing_train_plot) > 0:\n",
    "    axes[0].barh(missing_train_plot.index, missing_train_plot.values, color='coral')\n",
    "    axes[0].set_xlabel('결측치 수')\n",
    "    axes[0].set_title('Train 데이터 결측치')\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, '결측치 없음', ha='center', va='center', fontsize=14)\n",
    "    axes[0].set_title('Train 데이터 결측치')\n",
    "\n",
    "# Test 결측치\n",
    "missing_test_plot = missing_test[missing_test > 0].sort_values(ascending=True)\n",
    "if len(missing_test_plot) > 0:\n",
    "    axes[1].barh(missing_test_plot.index, missing_test_plot.values, color='steelblue')\n",
    "    axes[1].set_xlabel('결측치 수')\n",
    "    axes[1].set_title('Test 데이터 결측치')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, '결측치 없음', ha='center', va='center', fontsize=14)\n",
    "    axes[1].set_title('Test 데이터 결측치')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 시간대별 대여량 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간대별 평균 대여량\n",
    "hourly_avg = train.groupby('hour')['count'].mean()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(hourly_avg.index, hourly_avg.values, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('시간 (Hour)')\n",
    "plt.ylabel('평균 대여량')\n",
    "plt.title('시간대별 평균 따릉이 대여량')\n",
    "plt.xticks(range(24))\n",
    "\n",
    "# 출퇴근 시간 강조\n",
    "plt.axvspan(7, 9, alpha=0.3, color='red', label='출근 시간')\n",
    "plt.axvspan(17, 19, alpha=0.3, color='orange', label='퇴근 시간')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"시간대별 평균 대여량 (상위 5개):\")\n",
    "print(hourly_avg.sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 기상 조건과 대여량 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기온과 대여량 관계\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 기온 vs 대여량\n",
    "axes[0, 0].scatter(train['hour_bef_temperature'], train['count'], alpha=0.3, s=10)\n",
    "axes[0, 0].set_xlabel('기온 (°C)')\n",
    "axes[0, 0].set_ylabel('대여량')\n",
    "axes[0, 0].set_title('기온 vs 대여량')\n",
    "\n",
    "# 습도 vs 대여량\n",
    "axes[0, 1].scatter(train['hour_bef_humidity'], train['count'], alpha=0.3, s=10, color='green')\n",
    "axes[0, 1].set_xlabel('습도 (%)')\n",
    "axes[0, 1].set_ylabel('대여량')\n",
    "axes[0, 1].set_title('습도 vs 대여량')\n",
    "\n",
    "# 풍속 vs 대여량\n",
    "axes[1, 0].scatter(train['hour_bef_windspeed'], train['count'], alpha=0.3, s=10, color='orange')\n",
    "axes[1, 0].set_xlabel('풍속 (m/s)')\n",
    "axes[1, 0].set_ylabel('대여량')\n",
    "axes[1, 0].set_title('풍속 vs 대여량')\n",
    "\n",
    "# 강수 여부별 대여량\n",
    "rain_group = train.groupby('hour_bef_precipitation')['count'].mean()\n",
    "axes[1, 1].bar(['비 안옴 (0)', '비 옴 (1)'], rain_group.values, color=['steelblue', 'coral'])\n",
    "axes[1, 1].set_ylabel('평균 대여량')\n",
    "axes[1, 1].set_title('강수 여부별 평균 대여량')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 히트맵\n",
    "corr_matrix = train.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('변수 간 상관관계 히트맵')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟과의 상관관계\n",
    "target_corr = corr_matrix['count'].drop('count').sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if x > 0 else 'red' for x in target_corr.values]\n",
    "plt.barh(target_corr.index, target_corr.values, color=colors)\n",
    "plt.xlabel('상관계수')\n",
    "plt.title('타겟(count)과의 상관관계')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"타겟(count)과의 상관관계:\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 대기질과 대여량 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대기질 관련 변수와 대여량\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 오존 vs 대여량\n",
    "axes[0].scatter(train['hour_bef_ozone'], train['count'], alpha=0.3, s=10)\n",
    "axes[0].set_xlabel('오존 농도 (ppm)')\n",
    "axes[0].set_ylabel('대여량')\n",
    "axes[0].set_title('오존 vs 대여량')\n",
    "\n",
    "# PM10 vs 대여량\n",
    "axes[1].scatter(train['hour_bef_pm10'], train['count'], alpha=0.3, s=10, color='brown')\n",
    "axes[1].set_xlabel('미세먼지 PM10 (μg/m³)')\n",
    "axes[1].set_ylabel('대여량')\n",
    "axes[1].set_title('PM10 vs 대여량')\n",
    "\n",
    "# PM2.5 vs 대여량\n",
    "axes[2].scatter(train['hour_bef_pm2.5'], train['count'], alpha=0.3, s=10, color='purple')\n",
    "axes[2].set_xlabel('초미세먼지 PM2.5 (μg/m³)')\n",
    "axes[2].set_ylabel('대여량')\n",
    "axes[2].set_title('PM2.5 vs 대여량')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 복사\n",
    "train_df = train.copy()\n",
    "test_df = test.copy()\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 있는 컬럼 확인\n",
    "cols_with_missing = train_df.columns[train_df.isnull().any()].tolist()\n",
    "print(f\"결측치가 있는 컬럼: {cols_with_missing}\")\n",
    "\n",
    "# 수치형 컬럼의 결측치를 중앙값으로 대체\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].isnull().sum() > 0:\n",
    "        median_val = train_df[col].median()\n",
    "        train_df[col].fillna(median_val, inplace=True)\n",
    "        print(f\"  {col}: 중앙값 {median_val:.2f}로 대체\")\n",
    "\n",
    "# Test 데이터도 동일하게 처리 (Train의 중앙값 사용)\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].isnull().sum() > 0:\n",
    "        # Train 데이터의 중앙값 사용\n",
    "        if col in train.columns:\n",
    "            median_val = train[col].median()\n",
    "        else:\n",
    "            median_val = test_df[col].median()\n",
    "        test_df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "print(\"\\n결측치 처리 완료!\")\n",
    "print(f\"Train 결측치: {train_df.isnull().sum().sum()}\")\n",
    "print(f\"Test 결측치: {test_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 이상치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 박스플롯으로 이상치 확인\n",
    "numeric_cols = ['hour_bef_temperature', 'hour_bef_windspeed', 'hour_bef_humidity',\n",
    "                'hour_bef_visibility', 'hour_bef_ozone', 'hour_bef_pm10', 'hour_bef_pm2.5']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    axes[i].boxplot(train_df[col].dropna())\n",
    "    axes[i].set_title(col.replace('hour_bef_', ''))\n",
    "\n",
    "# 마지막 subplot에 타겟 변수\n",
    "axes[7].boxplot(train_df['count'])\n",
    "axes[7].set_title('count (Target)')\n",
    "\n",
    "plt.suptitle('변수별 박스플롯 (이상치 확인)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 특성 공학 (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    새로운 특성을 생성하는 함수\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. 시간대 구분 (출근/퇴근/주간/야간)\n",
    "    def get_time_period(hour):\n",
    "        if 7 <= hour <= 9:\n",
    "            return 'morning_rush'    # 출근 시간\n",
    "        elif 17 <= hour <= 19:\n",
    "            return 'evening_rush'    # 퇴근 시간\n",
    "        elif 10 <= hour <= 16:\n",
    "            return 'daytime'         # 주간\n",
    "        elif 20 <= hour <= 23:\n",
    "            return 'evening'         # 저녁\n",
    "        else:\n",
    "            return 'night'           # 야간 (0-6시)\n",
    "    \n",
    "    df['time_period'] = df['hour'].apply(get_time_period)\n",
    "    \n",
    "    # 2. 러시아워 여부\n",
    "    df['is_rush_hour'] = df['hour'].apply(lambda x: 1 if (7 <= x <= 9) or (17 <= x <= 19) else 0)\n",
    "    \n",
    "    # 3. 주간/야간 구분\n",
    "    df['is_daytime'] = df['hour'].apply(lambda x: 1 if 6 <= x <= 20 else 0)\n",
    "    \n",
    "    # 4. 시간 사이클 특성 (시간의 주기성 반영)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    \n",
    "    # 5. 기온 구간 (쾌적한 온도 여부)\n",
    "    df['is_comfortable_temp'] = df['hour_bef_temperature'].apply(\n",
    "        lambda x: 1 if 15 <= x <= 25 else 0\n",
    "    )\n",
    "    \n",
    "    # 6. 체감 불쾌 지수 (간단 버전)\n",
    "    # 불쾌지수 = 0.81*기온 + 0.01*습도*(0.99*기온-14.3) + 46.3\n",
    "    df['discomfort_index'] = (\n",
    "        0.81 * df['hour_bef_temperature'] + \n",
    "        0.01 * df['hour_bef_humidity'] * (0.99 * df['hour_bef_temperature'] - 14.3) + 46.3\n",
    "    )\n",
    "    \n",
    "    # 7. 미세먼지 등급\n",
    "    def pm10_grade(pm10):\n",
    "        if pm10 <= 30:\n",
    "            return 1  # 좋음\n",
    "        elif pm10 <= 80:\n",
    "            return 2  # 보통\n",
    "        elif pm10 <= 150:\n",
    "            return 3  # 나쁨\n",
    "        else:\n",
    "            return 4  # 매우 나쁨\n",
    "    \n",
    "    df['pm10_grade'] = df['hour_bef_pm10'].apply(pm10_grade)\n",
    "    \n",
    "    # 8. 초미세먼지 등급\n",
    "    def pm25_grade(pm25):\n",
    "        if pm25 <= 15:\n",
    "            return 1  # 좋음\n",
    "        elif pm25 <= 35:\n",
    "            return 2  # 보통\n",
    "        elif pm25 <= 75:\n",
    "            return 3  # 나쁨\n",
    "        else:\n",
    "            return 4  # 매우 나쁨\n",
    "    \n",
    "    df['pm25_grade'] = df['hour_bef_pm2.5'].apply(pm25_grade)\n",
    "    \n",
    "    # 9. 날씨 종합 점수 (자전거 타기 좋은 날씨)\n",
    "    # 비 안오고, 적당한 온도, 낮은 미세먼지, 적당한 풍속\n",
    "    df['good_weather_score'] = (\n",
    "        (1 - df['hour_bef_precipitation']) * 2 +  # 비 안오면 +2\n",
    "        df['is_comfortable_temp'] * 2 +           # 쾌적한 온도면 +2\n",
    "        (df['pm10_grade'] <= 2).astype(int) +     # 미세먼지 보통 이하면 +1\n",
    "        (df['hour_bef_windspeed'] <= 5).astype(int)  # 풍속 5m/s 이하면 +1\n",
    "    )\n",
    "    \n",
    "    # 10. 가시거리 등급\n",
    "    df['visibility_grade'] = pd.cut(\n",
    "        df['hour_bef_visibility'],\n",
    "        bins=[0, 200, 500, 1000, 2000, float('inf')],\n",
    "        labels=[1, 2, 3, 4, 5]\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 특성 생성\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)\n",
    "\n",
    "print(f\"특성 생성 후 Train shape: {train_df.shape}\")\n",
    "print(f\"특성 생성 후 Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 특성 확인\n",
    "new_features = ['time_period', 'is_rush_hour', 'is_daytime', 'hour_sin', 'hour_cos',\n",
    "                'is_comfortable_temp', 'discomfort_index', 'pm10_grade', 'pm25_grade',\n",
    "                'good_weather_score', 'visibility_grade']\n",
    "\n",
    "print(\"새로 생성된 특성:\")\n",
    "train_df[new_features].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 특성 원-핫 인코딩\n",
    "train_df = pd.get_dummies(train_df, columns=['time_period'], prefix='time')\n",
    "test_df = pd.get_dummies(test_df, columns=['time_period'], prefix='time')\n",
    "\n",
    "# Train에는 있지만 Test에 없는 컬럼 처리 (또는 그 반대)\n",
    "train_cols = set(train_df.columns)\n",
    "test_cols = set(test_df.columns)\n",
    "\n",
    "# Test에 없는 컬럼 추가\n",
    "for col in train_cols - test_cols:\n",
    "    if col != 'count':  # 타겟 제외\n",
    "        test_df[col] = 0\n",
    "\n",
    "# Train에 없는 컬럼 추가\n",
    "for col in test_cols - train_cols:\n",
    "    train_df[col] = 0\n",
    "\n",
    "print(f\"원-핫 인코딩 후 Train shape: {train_df.shape}\")\n",
    "print(f\"원-핫 인코딩 후 Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 새로운 특성과 타겟 간의 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 특성과 타겟 간의 관계 시각화\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 러시아워 여부별 대여량\n",
    "rush_hour_avg = train_df.groupby('is_rush_hour')['count'].mean()\n",
    "axes[0, 0].bar(['일반 시간', '러시아워'], rush_hour_avg.values, color=['steelblue', 'coral'])\n",
    "axes[0, 0].set_ylabel('평균 대여량')\n",
    "axes[0, 0].set_title('러시아워 여부별 평균 대여량')\n",
    "\n",
    "# 쾌적한 온도 여부별 대여량\n",
    "temp_avg = train_df.groupby('is_comfortable_temp')['count'].mean()\n",
    "axes[0, 1].bar(['불쾌적 온도', '쾌적 온도'], temp_avg.values, color=['coral', 'green'])\n",
    "axes[0, 1].set_ylabel('평균 대여량')\n",
    "axes[0, 1].set_title('온도 쾌적성별 평균 대여량')\n",
    "\n",
    "# 미세먼지 등급별 대여량\n",
    "pm_avg = train_df.groupby('pm10_grade')['count'].mean()\n",
    "axes[0, 2].bar(['좋음', '보통', '나쁨', '매우나쁨'], pm_avg.values, color='steelblue')\n",
    "axes[0, 2].set_ylabel('평균 대여량')\n",
    "axes[0, 2].set_title('미세먼지 등급별 평균 대여량')\n",
    "\n",
    "# 날씨 종합 점수별 대여량\n",
    "weather_avg = train_df.groupby('good_weather_score')['count'].mean()\n",
    "axes[1, 0].bar(weather_avg.index, weather_avg.values, color='green')\n",
    "axes[1, 0].set_xlabel('날씨 종합 점수')\n",
    "axes[1, 0].set_ylabel('평균 대여량')\n",
    "axes[1, 0].set_title('날씨 점수별 평균 대여량')\n",
    "\n",
    "# 불쾌지수 vs 대여량\n",
    "axes[1, 1].scatter(train_df['discomfort_index'], train_df['count'], alpha=0.3, s=10)\n",
    "axes[1, 1].set_xlabel('불쾌지수')\n",
    "axes[1, 1].set_ylabel('대여량')\n",
    "axes[1, 1].set_title('불쾌지수 vs 대여량')\n",
    "\n",
    "# 주간/야간별 대여량\n",
    "daytime_avg = train_df.groupby('is_daytime')['count'].mean()\n",
    "axes[1, 2].bar(['야간', '주간'], daytime_avg.values, color=['navy', 'orange'])\n",
    "axes[1, 2].set_ylabel('평균 대여량')\n",
    "axes[1, 2].set_title('주간/야간별 평균 대여량')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성과 타겟 분리\n",
    "target = 'count'\n",
    "features = [col for col in train_df.columns if col not in ['id', 'count']]\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[target]\n",
    "\n",
    "X_test = test_df[features]\n",
    "test_ids = test_df['id']\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"\\n사용할 특성 ({len(features)}개):\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수\n",
    "def evaluate_model(y_true, y_pred, model_name='Model'):\n",
    "    \"\"\"모델 성능 평가\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} 성능:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    \n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# 결과 저장\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_val)\n",
    "results['Linear Regression'] = evaluate_model(y_val, y_pred_lr, 'Linear Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge(alpha=1.0, random_state=42)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_val)\n",
    "results['Ridge'] = evaluate_model(y_val, y_pred_ridge, 'Ridge Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "results['Random Forest'] = evaluate_model(y_val, y_pred_rf, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gb = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb.predict(X_val)\n",
    "results['Gradient Boosting'] = evaluate_model(y_val, y_pred_gb, 'Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "results['XGBoost'] = evaluate_model(y_val, y_pred_xgb, 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)]\n",
    ")\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_val)\n",
    "results['LightGBM'] = evaluate_model(y_val, y_pred_lgb, 'LightGBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 모델 평가 및 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 비교\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('rmse')\n",
    "\n",
    "print('=' * 60)\n",
    "print('모델 성능 비교 (RMSE 기준 정렬)')\n",
    "print('=' * 60)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE 비교\n",
    "colors = ['green' if x == results_df['rmse'].min() else 'steelblue' for x in results_df['rmse']]\n",
    "axes[0].barh(results_df.index, results_df['rmse'], color=colors)\n",
    "axes[0].set_xlabel('RMSE')\n",
    "axes[0].set_title('모델별 RMSE (낮을수록 좋음)')\n",
    "\n",
    "# R² 비교\n",
    "colors = ['green' if x == results_df['r2'].max() else 'steelblue' for x in results_df['r2']]\n",
    "axes[1].barh(results_df.index, results_df['r2'], color=colors)\n",
    "axes[1].set_xlabel('R² Score')\n",
    "axes[1].set_title('모델별 R² (높을수록 좋음)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'][:15], feature_importance['importance'][:15])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('LightGBM Feature Importance (상위 15개)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Importance (상위 10개):\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 예측 vs 실제 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 vs 실제 산점도 (최고 성능 모델)\n",
    "best_model_name = results_df['rmse'].idxmin()\n",
    "print(f\"최고 성능 모델: {best_model_name}\")\n",
    "\n",
    "# 최고 성능 모델의 예측값 선택\n",
    "if best_model_name == 'LightGBM':\n",
    "    best_pred = y_pred_lgb\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_pred = y_pred_xgb\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_pred = y_pred_rf\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    best_pred = y_pred_gb\n",
    "else:\n",
    "    best_pred = y_pred_lgb  # 기본값\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 산점도\n",
    "axes[0].scatter(y_val, best_pred, alpha=0.5, s=20)\n",
    "max_val = max(y_val.max(), max(best_pred))\n",
    "axes[0].plot([0, max_val], [0, max_val], 'r--', label='Perfect Prediction')\n",
    "axes[0].set_xlabel('실제 대여량')\n",
    "axes[0].set_ylabel('예측 대여량')\n",
    "axes[0].set_title(f'{best_model_name}: 실제 vs 예측')\n",
    "axes[0].legend()\n",
    "\n",
    "# 잔차 분포\n",
    "residuals = y_val - best_pred\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('잔차 (실제 - 예측)')\n",
    "axes[1].set_ylabel('빈도')\n",
    "axes[1].set_title(f'{best_model_name}: 잔차 분포')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 최종 예측 및 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation으로 최종 모델 학습\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# OOF predictions\n",
    "oof_lgb = np.zeros(len(X))\n",
    "test_preds_lgb = np.zeros(len(X_test))\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n===== Fold {fold + 1}/{n_folds} =====\")\n",
    "    \n",
    "    X_tr, X_vl = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_tr, y_vl = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # LightGBM\n",
    "    lgb_fold = lgb.LGBMRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    lgb_fold.fit(X_tr, y_tr, eval_set=[(X_vl, y_vl)])\n",
    "    \n",
    "    oof_lgb[val_idx] = lgb_fold.predict(X_vl)\n",
    "    test_preds_lgb += lgb_fold.predict(X_test) / n_folds\n",
    "    \n",
    "    # Fold RMSE\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_vl, oof_lgb[val_idx]))\n",
    "    cv_scores.append(fold_rmse)\n",
    "    print(f\"Fold {fold + 1} RMSE: {fold_rmse:.4f}\")\n",
    "\n",
    "print(f\"\\n===== Cross Validation 결과 =====\")\n",
    "print(f\"평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOF 전체 성능\n",
    "oof_rmse = np.sqrt(mean_squared_error(y, oof_lgb))\n",
    "print(f\"OOF RMSE: {oof_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음수 예측값 처리 (대여량은 0 이상)\n",
    "test_preds_lgb = np.maximum(test_preds_lgb, 0)\n",
    "\n",
    "print(f\"예측값 통계:\")\n",
    "print(f\"  최소: {test_preds_lgb.min():.2f}\")\n",
    "print(f\"  최대: {test_preds_lgb.max():.2f}\")\n",
    "print(f\"  평균: {test_preds_lgb.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'count': test_preds_lgb\n",
    "})\n",
    "\n",
    "# 저장\n",
    "submission_df.to_csv('submission_seoul_bike.csv', index=False)\n",
    "\n",
    "print(\"제출 파일 생성 완료!\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 분포 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Train vs Test 예측 분포\n",
    "axes[0].hist(y, bins=50, alpha=0.5, label='Train (실제)', density=True)\n",
    "axes[0].hist(test_preds_lgb, bins=50, alpha=0.5, label='Test (예측)', density=True)\n",
    "axes[0].set_xlabel('대여량')\n",
    "axes[0].set_ylabel('밀도')\n",
    "axes[0].set_title('Train 실제 vs Test 예측 분포')\n",
    "axes[0].legend()\n",
    "\n",
    "# 시간대별 예측 평균\n",
    "test_df_pred = test_df.copy()\n",
    "test_df_pred['predicted_count'] = test_preds_lgb\n",
    "hourly_pred = test_df_pred.groupby('hour')['predicted_count'].mean()\n",
    "\n",
    "axes[1].bar(hourly_pred.index, hourly_pred.values, color='coral', edgecolor='black')\n",
    "axes[1].set_xlabel('시간 (Hour)')\n",
    "axes[1].set_ylabel('평균 예측 대여량')\n",
    "axes[1].set_title('시간대별 평균 예측 대여량')\n",
    "axes[1].set_xticks(range(24))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 8. AutoGluon 모델링\n\n**AutoGluon**은 Amazon에서 개발한 AutoML 라이브러리로, 자동으로 여러 모델을 학습하고 앙상블합니다.\n\n### AutoGluon Presets\n\n| Preset | 설명 | 학습 시간 | 성능 |\n|--------|------|----------|------|\n| `medium_quality` | 빠른 학습, 중간 성능 | 짧음 | 중간 |\n| `best_quality` | 최고 성능, 스태킹 앙상블 | 김 | 최고 |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# AutoGluon 라이브러리 로드\nfrom autogluon.tabular import TabularDataset, TabularPredictor\n\nprint(\"AutoGluon 라이브러리 로드 완료!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.1 AutoGluon용 데이터 준비\n\nAutoGluon은 자동 전처리를 수행하므로 원본 데이터를 사용합니다.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# AutoGluon용 데이터 준비\n# 특성 공학이 적용된 데이터 사용 (train_df, test_df)\n\n# AutoGluon용 데이터프레임 생성\ntrain_ag = train_df.copy()\ntest_ag = test_df.copy()\n\n# id 컬럼 제거 (AutoGluon은 자동으로 처리)\ntrain_ag = train_ag.drop(columns=['id'], errors='ignore')\ntest_ag_ids = test_df['id'].copy()\ntest_ag = test_ag.drop(columns=['id'], errors='ignore')\n\n# 타겟 컬럼명\ntarget_col = 'count'\n\nprint(f\"AutoGluon Train shape: {train_ag.shape}\")\nprint(f\"AutoGluon Test shape: {test_ag.shape}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.2 AutoGluon - Medium Quality 모델\n\n빠른 학습과 적당한 성능을 제공하는 프리셋입니다.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# AutoGluon Medium Quality 모델 학습\npredictor_medium = TabularPredictor(\n    label=target_col,\n    problem_type='regression',\n    eval_metric='root_mean_squared_error',\n    path='AutoGluon_SeoulBike_medium'\n)\n\n# 모델 학습 (tuning_data 없이 - medium_quality는 bagging 사용 안함)\npredictor_medium.fit(\n    train_data=train_ag,\n    presets='medium_quality',\n    time_limit=180,              # 3분\n    verbosity=2\n)\n\nprint('\\n===== AutoGluon Medium Quality 학습 완료! =====')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Medium Quality 모델 리더보드 확인\nprint('===== AutoGluon Medium Quality - 모델 리더보드 =====')\nleaderboard_medium = predictor_medium.leaderboard(silent=True)\nprint(leaderboard_medium)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Medium Quality 모델로 검증 데이터 예측 및 평가\n# Train/Validation 분할 (이전과 동일한 분할 사용)\ntrain_ag_split, val_ag_split = train_test_split(train_ag, test_size=0.2, random_state=42)\n\ny_pred_ag_medium = predictor_medium.predict(val_ag_split.drop(columns=[target_col]))\ny_true_ag = val_ag_split[target_col]\n\n# 성능 평가\nrmse_medium = np.sqrt(mean_squared_error(y_true_ag, y_pred_ag_medium))\nmae_medium = mean_absolute_error(y_true_ag, y_pred_ag_medium)\nr2_medium = r2_score(y_true_ag, y_pred_ag_medium)\n\nprint('\\n===== AutoGluon Medium Quality 성능 =====')\nprint(f'  RMSE: {rmse_medium:.4f}')\nprint(f'  MAE:  {mae_medium:.4f}')\nprint(f'  R²:   {r2_medium:.4f}')\n\n# 결과 저장\nresults['AutoGluon (Medium)'] = {'rmse': rmse_medium, 'mae': mae_medium, 'r2': r2_medium}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.3 AutoGluon - Best Quality 모델\n\n최고 성능을 위한 프리셋으로, 스태킹 앙상블과 K-Fold CV를 수행합니다.\n\n**참고**: `best_quality` 프리셋은 bagging 모드를 사용하므로 `tuning_data` 없이 학습합니다.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# AutoGluon Best Quality 모델 학습\npredictor_best = TabularPredictor(\n    label=target_col,\n    problem_type='regression',\n    eval_metric='root_mean_squared_error',\n    path='AutoGluon_SeoulBike_best'\n)\n\n# 모델 학습 (best_quality는 tuning_data 없이!)\npredictor_best.fit(\n    train_data=train_ag,\n    presets='best_quality',\n    time_limit=300,              # 5분\n    verbosity=2\n)\n\nprint('\\n===== AutoGluon Best Quality 학습 완료! =====')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Best Quality 모델 리더보드 확인\nprint('===== AutoGluon Best Quality - 모델 리더보드 =====')\nleaderboard_best = predictor_best.leaderboard(silent=True)\nprint(leaderboard_best)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Best Quality 모델로 검증 데이터 예측 및 평가\ny_pred_ag_best = predictor_best.predict(val_ag_split.drop(columns=[target_col]))\n\n# 성능 평가\nrmse_best = np.sqrt(mean_squared_error(y_true_ag, y_pred_ag_best))\nmae_best = mean_absolute_error(y_true_ag, y_pred_ag_best)\nr2_best = r2_score(y_true_ag, y_pred_ag_best)\n\nprint('\\n===== AutoGluon Best Quality 성능 =====')\nprint(f'  RMSE: {rmse_best:.4f}')\nprint(f'  MAE:  {mae_best:.4f}')\nprint(f'  R²:   {r2_best:.4f}')\n\n# 결과 저장\nresults['AutoGluon (Best)'] = {'rmse': rmse_best, 'mae': mae_best, 'r2': r2_best}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.4 전체 모델 성능 비교 (기존 모델 + AutoGluon)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 전체 모델 성능 비교 (AutoGluon 포함)\nresults_df_all = pd.DataFrame(results).T\nresults_df_all = results_df_all.sort_values('rmse')\n\nprint('=' * 70)\nprint('전체 모델 성능 비교 (RMSE 기준 정렬) - AutoGluon 포함')\nprint('=' * 70)\nprint(results_df_all)\n\n# 최고 성능 모델\nbest_model = results_df_all['rmse'].idxmin()\nprint(f\"\\n최고 성능 모델: {best_model}\")\nprint(f\"  RMSE: {results_df_all.loc[best_model, 'rmse']:.4f}\")\nprint(f\"  R²:   {results_df_all.loc[best_model, 'r2']:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 전체 모델 성능 시각화 (AutoGluon 강조)\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# AutoGluon 모델 강조 색상\ndef get_color(model_name):\n    if 'AutoGluon' in model_name:\n        if 'Best' in model_name:\n            return 'darkgreen'\n        return 'lightgreen'\n    return 'steelblue'\n\ncolors_rmse = [get_color(idx) for idx in results_df_all.index]\n\n# RMSE 비교\naxes[0].barh(results_df_all.index, results_df_all['rmse'], color=colors_rmse, edgecolor='black')\naxes[0].set_xlabel('RMSE')\naxes[0].set_title('전체 모델 RMSE 비교 (낮을수록 좋음)\\n(녹색: AutoGluon)')\naxes[0].axvline(x=results_df_all['rmse'].min(), color='red', linestyle='--', alpha=0.7)\n\n# R² 비교\naxes[1].barh(results_df_all.index, results_df_all['r2'], color=colors_rmse, edgecolor='black')\naxes[1].set_xlabel('R² Score')\naxes[1].set_title('전체 모델 R² 비교 (높을수록 좋음)\\n(녹색: AutoGluon)')\naxes[1].axvline(x=results_df_all['r2'].max(), color='red', linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# AutoGluon Best Quality Feature Importance\nprint('===== AutoGluon Best Quality - Feature Importance =====')\nimportance_ag = predictor_best.feature_importance(train_ag)\nprint(importance_ag.head(15))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.5 AutoGluon 테스트 데이터 예측 및 제출 파일 생성",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# AutoGluon Best Quality 모델로 테스트 데이터 예측\ntest_preds_ag = predictor_best.predict(test_ag)\n\n# 음수 값 처리 (대여량은 0 이상)\ntest_preds_ag = np.maximum(test_preds_ag, 0)\n\nprint(f\"AutoGluon 예측 완료!\")\nprint(f\"예측값 통계:\")\nprint(f\"  최소: {test_preds_ag.min():.2f}\")\nprint(f\"  최대: {test_preds_ag.max():.2f}\")\nprint(f\"  평균: {test_preds_ag.mean():.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# AutoGluon 제출 파일 생성\nsubmission_ag = pd.DataFrame({\n    'id': test_ag_ids,\n    'count': test_preds_ag\n})\n\n# 저장\nsubmission_ag.to_csv('submission_autogluon.csv', index=False)\n\nprint(\"AutoGluon 제출 파일 생성 완료!\")\nprint(submission_ag.head(10))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Summary\n\n### 수행한 작업\n\n1. **EDA (탐색적 데이터 분석)**\n   - 타겟 변수(대여량) 분포 분석\n   - 시간대별, 기상 조건별 대여량 패턴 분석\n   - 상관관계 분석\n\n2. **데이터 전처리**\n   - 결측치 처리 (중앙값 대체)\n   - 이상치 확인\n\n3. **특성 공학**\n   - 시간대 구분 (출근/퇴근/주간/야간)\n   - 러시아워 플래그\n   - 시간 사이클 특성 (sin/cos)\n   - 불쾌지수\n   - 미세먼지/초미세먼지 등급\n   - 날씨 종합 점수\n\n4. **모델링**\n   - Linear Regression, Ridge\n   - Random Forest, Gradient Boosting\n   - XGBoost, LightGBM\n\n5. **AutoGluon 모델링 (NEW)**\n   - Medium Quality: 빠른 학습, 중간 성능\n   - Best Quality: 스태킹 앙상블, 최고 성능\n\n6. **모델 평가**\n   - RMSE, MAE, R² 기반 비교\n   - 기존 모델 vs AutoGluon 성능 비교\n   - K-Fold Cross Validation\n\n### 주요 인사이트\n\n- **시간대**: 출퇴근 시간(8시, 18시)에 대여량이 가장 많음\n- **기온**: 15-25°C의 쾌적한 온도에서 대여량 증가\n- **강수**: 비가 오면 대여량이 크게 감소\n- **미세먼지**: 미세먼지가 나쁘면 대여량 감소\n\n### 생성된 파일\n- `submission_seoul_bike.csv`: LightGBM K-Fold 예측 제출 파일\n- `submission_autogluon.csv`: AutoGluon Best Quality 예측 제출 파일",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### 수행한 작업\n",
    "\n",
    "1. **EDA (탐색적 데이터 분석)**\n",
    "   - 타겟 변수(대여량) 분포 분석\n",
    "   - 시간대별, 기상 조건별 대여량 패턴 분석\n",
    "   - 상관관계 분석\n",
    "\n",
    "2. **데이터 전처리**\n",
    "   - 결측치 처리 (중앙값 대체)\n",
    "   - 이상치 확인\n",
    "\n",
    "3. **특성 공학**\n",
    "   - 시간대 구분 (출근/퇴근/주간/야간)\n",
    "   - 러시아워 플래그\n",
    "   - 시간 사이클 특성 (sin/cos)\n",
    "   - 불쾌지수\n",
    "   - 미세먼지/초미세먼지 등급\n",
    "   - 날씨 종합 점수\n",
    "\n",
    "4. **모델링**\n",
    "   - Linear Regression, Ridge\n",
    "   - Random Forest, Gradient Boosting\n",
    "   - XGBoost, LightGBM\n",
    "\n",
    "5. **모델 평가**\n",
    "   - RMSE, MAE, R² 기반 비교\n",
    "   - K-Fold Cross Validation\n",
    "\n",
    "### 주요 인사이트\n",
    "\n",
    "- **시간대**: 출퇴근 시간(8시, 18시)에 대여량이 가장 많음\n",
    "- **기온**: 15-25°C의 쾌적한 온도에서 대여량 증가\n",
    "- **강수**: 비가 오면 대여량이 크게 감소\n",
    "- **미세먼지**: 미세먼지가 나쁘면 대여량 감소\n",
    "\n",
    "### 생성된 파일\n",
    "- `submission_seoul_bike.csv`: 최종 예측 제출 파일"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}