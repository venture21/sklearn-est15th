{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# AutoGluon을 활용한 앙상블 모델 하이퍼파라미터 최적화\n",
    "## California Housing Dataset\n",
    "\n",
    "이 노트북에서는 AutoGluon의 자동 하이퍼파라미터 튜닝 기능을 사용하여\n",
    "GBM, AdaBoost, XGBoost, LightGBM 모델을 최적화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoGluon 설치 (처음 실행 시 필요)\n",
    "!pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# numpy 소수점 4째자리까지 표현\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "### 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing()\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "df['MedHouseVal'] = data['target']\n",
    "\n",
    "print(f\"데이터셋 크기: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-header",
   "metadata": {},
   "source": [
    "### 데이터 분할 (Train/Test Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# AutoGluon은 DataFrame 형태로 데이터를 받음\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train set: {train_df.shape}\")\n",
    "print(f\"Test set: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autogluon-header",
   "metadata": {},
   "source": [
    "---\n",
    "## AutoGluon을 사용한 모델 최적화\n",
    "\n",
    "AutoGluon은 자동 머신러닝(AutoML) 라이브러리로, 하이퍼파라미터 튜닝을 자동으로 수행합니다.\n",
    "\n",
    "**사용할 모델:**\n",
    "- **GBM (LightGBM)**: AutoGluon 내장 LightGBM\n",
    "- **XGB (XGBoost)**: AutoGluon 내장 XGBoost  \n",
    "- **CAT (CatBoost)**: AutoGluon 내장 CatBoost\n",
    "- **RF (Random Forest)**: sklearn 기반 Random Forest\n",
    "\n",
    "> 참고: sklearn의 GradientBoostingRegressor와 AdaBoostRegressor는 AutoGluon에서 직접 지원하지 않으므로,\n",
    "> AutoGluon 학습 후 별도로 최적화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autogluon-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from autogluon.common import space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparams-header",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 검색 공간 정의\n",
    "\n",
    "AutoGluon의 `space` 모듈을 사용하여 하이퍼파라미터 검색 범위를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hyperparams-define",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 하이퍼파라미터 검색 공간 정의\n",
    "hyperparameters = {\n",
    "    # LightGBM (GBM)\n",
    "    'GBM': [\n",
    "        {\n",
    "            'num_boost_round': space.Int(100, 1000, default=500),\n",
    "            'learning_rate': space.Real(0.01, 0.3, default=0.1, log=True),\n",
    "            'num_leaves': space.Int(20, 100, default=31),\n",
    "            'max_depth': space.Int(3, 10, default=6),\n",
    "            'min_data_in_leaf': space.Int(10, 100, default=20),\n",
    "            'feature_fraction': space.Real(0.5, 1.0, default=0.8),\n",
    "            'bagging_fraction': space.Real(0.5, 1.0, default=0.8),\n",
    "            'bagging_freq': space.Int(1, 10, default=5),\n",
    "            'lambda_l1': space.Real(0.0, 1.0, default=0.0),\n",
    "            'lambda_l2': space.Real(0.0, 1.0, default=0.0),\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    # XGBoost\n",
    "    'XGB': [\n",
    "        {\n",
    "            'n_estimators': space.Int(100, 1000, default=500),\n",
    "            'learning_rate': space.Real(0.01, 0.3, default=0.1, log=True),\n",
    "            'max_depth': space.Int(3, 10, default=6),\n",
    "            'min_child_weight': space.Int(1, 10, default=1),\n",
    "            'subsample': space.Real(0.5, 1.0, default=0.8),\n",
    "            'colsample_bytree': space.Real(0.5, 1.0, default=0.8),\n",
    "            'gamma': space.Real(0, 1, default=0),\n",
    "            'reg_alpha': space.Real(0, 1, default=0),\n",
    "            'reg_lambda': space.Real(0, 1, default=1),\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    # CatBoost\n",
    "    'CAT': [\n",
    "        {\n",
    "            'iterations': space.Int(100, 1000, default=500),\n",
    "            'learning_rate': space.Real(0.01, 0.3, default=0.1, log=True),\n",
    "            'depth': space.Int(4, 10, default=6),\n",
    "            'l2_leaf_reg': space.Real(1, 10, default=3),\n",
    "            'random_strength': space.Real(0, 1, default=0.5),\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    # Random Forest (배깅 기반)\n",
    "    'RF': [\n",
    "        {\n",
    "            'n_estimators': space.Int(100, 500, default=300),\n",
    "            'max_depth': space.Int(5, 20, default=None),\n",
    "            'min_samples_split': space.Int(2, 20, default=2),\n",
    "            'min_samples_leaf': space.Int(1, 10, default=1),\n",
    "            'max_features': space.Real(0.5, 1.0, default=0.8),\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"하이퍼파라미터 검색 공간이 정의되었습니다.\")\n",
    "print(f\"튜닝할 모델: {list(hyperparameters.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "### AutoGluon 학습 및 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-autogluon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabularPredictor 생성 및 학습\n",
    "predictor = TabularPredictor(\n",
    "    label='MedHouseVal',\n",
    "    eval_metric='root_mean_squared_error',\n",
    "    path='autogluon_models'\n",
    ")\n",
    "\n",
    "# 하이퍼파라미터 튜닝 설정\n",
    "hyperparameter_tune_kwargs = {\n",
    "    'num_trials': 30,           # 각 모델당 시도할 하이퍼파라미터 조합 수\n",
    "    'scheduler': 'local',       # 로컬 스케줄러 사용\n",
    "    'searcher': 'auto',         # 자동 탐색 알고리즘 선택\n",
    "}\n",
    "\n",
    "# 모델 학습\n",
    "predictor.fit(\n",
    "    train_data=train_df,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "    time_limit=600,             # 최대 10분 (초 단위)\n",
    "    presets='best_quality',     # 최고 품질 프리셋\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "### AutoGluon 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leaderboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리더보드 확인\n",
    "leaderboard = predictor.leaderboard(test_df, silent=True)\n",
    "print(\"=\" * 80)\n",
    "print(\"AutoGluon 모델 리더보드\")\n",
    "print(\"=\" * 80)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "best-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 모델 정보\n",
    "print(f\"\\n최적 모델: {predictor.model_best}\")\n",
    "print(f\"\\n모델별 성능 요약:\")\n",
    "print(predictor.fit_summary(show_plot=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 확인\n",
    "importance = predictor.feature_importance(test_df)\n",
    "print(\"\\n특성 중요도:\")\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "### 테스트 데이터 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 예측\n",
    "y_test = test_df['MedHouseVal']\n",
    "y_pred = predictor.predict(test_df)\n",
    "\n",
    "# 평가 지표 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"AutoGluon 최적 모델 평가 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:  {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"R2:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 vs 실제값 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5, edgecolors='k', linewidths=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Values', fontsize=12)\n",
    "plt.ylabel('Predicted Values', fontsize=12)\n",
    "plt.title(f'AutoGluon Best Model: Predicted vs Actual\\n(RMSE: {rmse:.4f}, R2: {r2:.4f})', fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sklearn-header",
   "metadata": {},
   "source": [
    "---\n",
    "## sklearn GradientBoosting & AdaBoost 최적화 (Optuna 사용)\n",
    "\n",
    "AutoGluon에서 직접 지원하지 않는 sklearn의 GradientBoostingRegressor와 AdaBoostRegressor는\n",
    "Optuna를 사용하여 하이퍼파라미터 튜닝을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna-install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# sklearn용 데이터 분할\n",
    "X_train = train_df.drop('MedHouseVal', axis=1)\n",
    "y_train_sk = train_df['MedHouseVal']\n",
    "X_test = test_df.drop('MedHouseVal', axis=1)\n",
    "y_test_sk = test_df['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gbm-sklearn-header",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gbm-optuna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'max_features': trial.suggest_float('max_features', 0.5, 1.0),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = GradientBoostingRegressor(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train_sk, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "# GBM 최적화 실행\n",
    "print(\"GradientBoostingRegressor 하이퍼파라미터 최적화 중...\")\n",
    "study_gbm = optuna.create_study(direction='minimize')\n",
    "study_gbm.optimize(objective_gbm, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n최적 MSE: {study_gbm.best_value:.4f}\")\n",
    "print(f\"최적 하이퍼파라미터: {study_gbm.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gbm-best",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 GBM 모델 학습 및 평가\n",
    "best_gbm = GradientBoostingRegressor(**study_gbm.best_params, random_state=42)\n",
    "best_gbm.fit(X_train, y_train_sk)\n",
    "y_pred_gbm = best_gbm.predict(X_test)\n",
    "\n",
    "mse_gbm = mean_squared_error(y_test_sk, y_pred_gbm)\n",
    "rmse_gbm = np.sqrt(mse_gbm)\n",
    "r2_gbm = r2_score(y_test_sk, y_pred_gbm)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"최적화된 GradientBoostingRegressor 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:  {mse_gbm:.4f}\")\n",
    "print(f\"RMSE: {rmse_gbm:.4f}\")\n",
    "print(f\"R2:   {r2_gbm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada-header",
   "metadata": {},
   "source": [
    "### AdaBoostRegressor 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada-optuna",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def objective_ada(trial):\n",
    "    base_max_depth = trial.suggest_int('base_max_depth', 2, 10)\n",
    "    params = {\n",
    "        'estimator': DecisionTreeRegressor(max_depth=base_max_depth, random_state=42),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 2.0, log=True),\n",
    "        'loss': trial.suggest_categorical('loss', ['linear', 'square', 'exponential']),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = AdaBoostRegressor(**params)\n",
    "    scores = cross_val_score(model, X_train, y_train_sk, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "# AdaBoost 최적화 실행\n",
    "print(\"AdaBoostRegressor 하이퍼파라미터 최적화 중...\")\n",
    "study_ada = optuna.create_study(direction='minimize')\n",
    "study_ada.optimize(objective_ada, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n최적 MSE: {study_ada.best_value:.4f}\")\n",
    "print(f\"최적 하이퍼파라미터: {study_ada.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada-best",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 AdaBoost 모델 학습 및 평가\n",
    "best_ada_params = study_ada.best_params.copy()\n",
    "base_max_depth = best_ada_params.pop('base_max_depth')\n",
    "best_ada = AdaBoostRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=base_max_depth, random_state=42),\n",
    "    **best_ada_params,\n",
    "    random_state=42\n",
    ")\n",
    "best_ada.fit(X_train, y_train_sk)\n",
    "y_pred_ada = best_ada.predict(X_test)\n",
    "\n",
    "mse_ada = mean_squared_error(y_test_sk, y_pred_ada)\n",
    "rmse_ada = np.sqrt(mse_ada)\n",
    "r2_ada = r2_score(y_test_sk, y_pred_ada)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"최적화된 AdaBoostRegressor 결과\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE:  {mse_ada:.4f}\")\n",
    "print(f\"RMSE: {rmse_ada:.4f}\")\n",
    "print(f\"R2:   {r2_ada:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 전체 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 결과 요약\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'MSE': [],\n",
    "    'RMSE': [],\n",
    "    'R2': []\n",
    "}\n",
    "\n",
    "# AutoGluon 모델들의 성능 추가\n",
    "for model_name in leaderboard['model'].values:\n",
    "    y_pred_model = predictor.predict(test_df, model=model_name)\n",
    "    mse_model = mean_squared_error(y_test, y_pred_model)\n",
    "    rmse_model = np.sqrt(mse_model)\n",
    "    r2_model = r2_score(y_test, y_pred_model)\n",
    "    \n",
    "    results['Model'].append(f\"AutoGluon_{model_name}\")\n",
    "    results['MSE'].append(mse_model)\n",
    "    results['RMSE'].append(rmse_model)\n",
    "    results['R2'].append(r2_model)\n",
    "\n",
    "# sklearn 모델들 추가\n",
    "results['Model'].append('Sklearn_GBM (Optuna)')\n",
    "results['MSE'].append(mse_gbm)\n",
    "results['RMSE'].append(rmse_gbm)\n",
    "results['R2'].append(r2_gbm)\n",
    "\n",
    "results['Model'].append('Sklearn_AdaBoost (Optuna)')\n",
    "results['MSE'].append(mse_ada)\n",
    "results['RMSE'].append(rmse_ada)\n",
    "results['R2'].append(r2_ada)\n",
    "\n",
    "# 결과 DataFrame 생성 및 정렬\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('RMSE').reset_index(drop=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"전체 모델 성능 비교 (RMSE 기준 정렬)\")\n",
    "print(\"=\" * 80)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 비교 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# RMSE 비교\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(results_df)))\n",
    "axes[0].barh(results_df['Model'], results_df['RMSE'], color=colors)\n",
    "axes[0].set_xlabel('RMSE', fontsize=12)\n",
    "axes[0].set_title('Model Comparison by RMSE', fontsize=14)\n",
    "axes[0].invert_yaxis()\n",
    "for i, v in enumerate(results_df['RMSE']):\n",
    "    axes[0].text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)\n",
    "\n",
    "# R2 비교\n",
    "axes[1].barh(results_df['Model'], results_df['R2'], color=colors)\n",
    "axes[1].set_xlabel('R2 Score', fontsize=12)\n",
    "axes[1].set_title('Model Comparison by R2 Score', fontsize=14)\n",
    "axes[1].invert_yaxis()\n",
    "for i, v in enumerate(results_df['R2']):\n",
    "    axes[1].text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best-params-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 최적 하이퍼파라미터 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "best-params",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"최적 하이퍼파라미터 요약\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[1] sklearn GradientBoostingRegressor (Optuna 최적화):\")\n",
    "for key, value in study_gbm.best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "print(\"\\n[2] sklearn AdaBoostRegressor (Optuna 최적화):\")\n",
    "for key, value in study_ada.best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "print(\"\\n[3] AutoGluon 최적 모델 정보:\")\n",
    "print(f\"    Best Model: {predictor.model_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autogluon-hyperparams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoGluon 모델별 하이퍼파라미터 확인\n",
    "print(\"\\n[AutoGluon 학습된 모델 정보]\")\n",
    "model_info = predictor.info()\n",
    "print(f\"모델 수: {model_info['model_info']['model_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "## 결론\n",
    "\n",
    "이 노트북에서는 AutoGluon과 Optuna를 사용하여 다양한 앙상블 모델의 하이퍼파라미터를 최적화했습니다.\n",
    "\n",
    "**사용된 모델:**\n",
    "- AutoGluon: LightGBM (GBM), XGBoost (XGB), CatBoost (CAT), Random Forest (RF)\n",
    "- Optuna: sklearn GradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "**주요 특징:**\n",
    "1. AutoGluon은 자동으로 하이퍼파라미터 튜닝과 모델 앙상블을 수행\n",
    "2. Optuna는 베이지안 최적화를 통해 효율적인 하이퍼파라미터 탐색 수행\n",
    "3. 모든 모델의 성능을 비교하여 최적의 모델 선택 가능"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
